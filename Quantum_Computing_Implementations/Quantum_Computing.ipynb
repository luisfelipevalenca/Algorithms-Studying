{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEDtIVb/oVEhSfo7f2J8E2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisfelipevalenca/Algorithms-Studying/blob/main/Quantum_Computing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tOAQTG05baR",
        "outputId": "40d6e2b1-84b8-431e-ae44-38289720c91a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-100. -100. -100. -100. -100.  100. -100. -100. -100. -100. -100.]\n",
            "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
            "[-100.   -1. -100. -100. -100. -100. -100.   -1. -100.   -1. -100.]\n",
            "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.   -1. -100.]\n",
            "[-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100.]\n",
            "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
            "[-100. -100. -100. -100. -100.   -1. -100. -100. -100. -100. -100.]\n",
            "[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n",
            "[-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100.]\n",
            "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
            "[-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.]\n",
            "Training complete!\n",
            "[[3, 9], [2, 9], [1, 9], [1, 8], [1, 7], [1, 6], [1, 5], [0, 5]]\n",
            "[[5, 0], [5, 1], [5, 2], [5, 3], [4, 3], [3, 3], [3, 2], [3, 1], [2, 1], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [0, 5]]\n",
            "[[9, 5], [9, 4], [9, 3], [8, 3], [7, 3], [7, 4], [7, 5], [6, 5], [5, 5], [5, 6], [5, 7], [4, 7], [3, 7], [2, 7], [1, 7], [1, 6], [1, 5], [0, 5]]\n",
            "[[0, 5], [1, 5], [1, 4], [1, 3], [1, 2], [1, 1], [2, 1], [3, 1], [3, 2], [3, 3], [4, 3], [5, 3], [5, 2]]\n"
          ]
        }
      ],
      "source": [
        "# Following Class\n",
        "\n",
        "#import libraries\n",
        "import numpy as np\n",
        "\n",
        "#define the shape of the environment (i.e., its states)\n",
        "environment_rows = 11\n",
        "environment_columns = 11\n",
        "\n",
        "#Create a 3D numpy array to hold the current Q-values for each state and action pair: Q(s, a)\n",
        "#The array contains 11 rows and 11 columns (to match the shape of the environment), as well as a third \"action\" dimension.\n",
        "#The \"action\" dimension consists of 4 layers that will allow us to keep track of the Q-values for each possible action in\n",
        "#each state (see next cell for a description of possible actions).\n",
        "#The value of each (state, action) pair is initialized to 0.\n",
        "q_values = np.zeros((environment_rows, environment_columns, 4))\n",
        "\n",
        "\n",
        "#define actions\n",
        "#numeric action codes: 0 = up, 1 = right, 2 = down, 3 = left\n",
        "actions = ['up', 'right', 'down', 'left']\n",
        "\n",
        "#Create a 2D numpy array to hold the rewards for each state.\n",
        "#The array contains 11 rows and 11 columns (to match the shape of the environment), and each value is initialized to -100.\n",
        "rewards = np.full((environment_rows, environment_columns), -100.)\n",
        "rewards[0, 5] = 100. #set the reward for the packaging area (i.e., the goal) to 100\n",
        "\n",
        "#define aisle locations (i.e., white squares) for rows 1 through 9\n",
        "aisles = {} #store locations in a dictionary\n",
        "aisles[1] = [i for i in range(1, 10)]\n",
        "aisles[2] = [1, 7, 9]\n",
        "aisles[3] = [i for i in range(1, 8)]\n",
        "aisles[3].append(9)\n",
        "aisles[4] = [3, 7]\n",
        "aisles[5] = [i for i in range(11)]\n",
        "aisles[6] = [5]\n",
        "aisles[7] = [i for i in range(1, 10)]\n",
        "aisles[8] = [3, 7]\n",
        "aisles[9] = [i for i in range(11)]\n",
        "\n",
        "#set the rewards for all aisle locations (i.e., white squares)\n",
        "for row_index in range(1, 10):\n",
        "  for column_index in aisles[row_index]:\n",
        "    rewards[row_index, column_index] = -1.\n",
        "\n",
        "#print rewards matrix\n",
        "for row in rewards:\n",
        "  print(row)\n",
        "\n",
        "#define a function that determines if the specified location is a terminal state\n",
        "def is_terminal_state(current_row_index, current_column_index):\n",
        "  #if the reward for this location is -1, then it is not a terminal state (i.e., it is a 'white square')\n",
        "  if rewards[current_row_index, current_column_index] == -1.:\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "\n",
        "#define a function that will choose a random, non-terminal starting location\n",
        "def get_starting_location():\n",
        "  #get a random row and column index\n",
        "  current_row_index = np.random.randint(environment_rows)\n",
        "  current_column_index = np.random.randint(environment_columns)\n",
        "  #continue choosing random row and column indexes until a non-terminal state is identified\n",
        "  #(i.e., until the chosen state is a 'white square').\n",
        "  while is_terminal_state(current_row_index, current_column_index):\n",
        "    current_row_index = np.random.randint(environment_rows)\n",
        "    current_column_index = np.random.randint(environment_columns)\n",
        "  return current_row_index, current_column_index\n",
        "\n",
        "#define an epsilon greedy algorithm that will choose which action to take next (i.e., where to move next)\n",
        "def get_next_action(current_row_index, current_column_index, epsilon):\n",
        "  #if a randomly chosen value between 0 and 1 is less than epsilon,\n",
        "  #then choose the most promising value from the Q-table for this state.\n",
        "  if np.random.random() < epsilon:\n",
        "    return np.argmax(q_values[current_row_index, current_column_index])\n",
        "  else: #choose a random action\n",
        "    return np.random.randint(4)\n",
        "\n",
        "#define a function that will get the next location based on the chosen action\n",
        "def get_next_location(current_row_index, current_column_index, action_index):\n",
        "  new_row_index = current_row_index\n",
        "  new_column_index = current_column_index\n",
        "  if actions[action_index] == 'up' and current_row_index > 0:\n",
        "    new_row_index -= 1\n",
        "  elif actions[action_index] == 'right' and current_column_index < environment_columns - 1:\n",
        "    new_column_index += 1\n",
        "  elif actions[action_index] == 'down' and current_row_index < environment_rows - 1:\n",
        "    new_row_index += 1\n",
        "  elif actions[action_index] == 'left' and current_column_index > 0:\n",
        "    new_column_index -= 1\n",
        "  return new_row_index, new_column_index\n",
        "\n",
        "#Define a function that will get the shortest path between any location within the warehouse that\n",
        "#the robot is allowed to travel and the item packaging location.\n",
        "def get_shortest_path(start_row_index, start_column_index):\n",
        "  #return immediately if this is an invalid starting location\n",
        "  if is_terminal_state(start_row_index, start_column_index):\n",
        "    return []\n",
        "  else: #if this is a 'legal' starting location\n",
        "    current_row_index, current_column_index = start_row_index, start_column_index\n",
        "    shortest_path = []\n",
        "    shortest_path.append([current_row_index, current_column_index])\n",
        "    #continue moving along the path until we reach the goal (i.e., the item packaging location)\n",
        "    while not is_terminal_state(current_row_index, current_column_index):\n",
        "      #get the best action to take\n",
        "      action_index = get_next_action(current_row_index, current_column_index, 1.)\n",
        "      #move to the next location on the path, and add the new location to the list\n",
        "      current_row_index, current_column_index = get_next_location(current_row_index, current_column_index, action_index)\n",
        "      shortest_path.append([current_row_index, current_column_index])\n",
        "    return shortest_path\n",
        "\n",
        "#define training parameters\n",
        "epsilon = 0.9 #the percentage of time when we should take the best action (instead of a random action)\n",
        "discount_factor = 0.9 #discount factor for future rewards\n",
        "learning_rate = 0.9 #the rate at which the AI agent should learn\n",
        "\n",
        "#run through 1000 training episodes\n",
        "for episode in range(1000):\n",
        "  #get the starting location for this episode\n",
        "  row_index, column_index = get_starting_location()\n",
        "\n",
        "  #continue taking actions (i.e., moving) until we reach a terminal state\n",
        "  #(i.e., until we reach the item packaging area or crash into an item storage location)\n",
        "  while not is_terminal_state(row_index, column_index):\n",
        "    #choose which action to take (i.e., where to move next)\n",
        "    action_index = get_next_action(row_index, column_index, epsilon)\n",
        "\n",
        "    #perform the chosen action, and transition to the next state (i.e., move to the next location)\n",
        "    old_row_index, old_column_index = row_index, column_index #store the old row and column indexes\n",
        "    row_index, column_index = get_next_location(row_index, column_index, action_index)\n",
        "\n",
        "    #receive the reward for moving to the new state, and calculate the temporal difference\n",
        "    reward = rewards[row_index, column_index]\n",
        "    old_q_value = q_values[old_row_index, old_column_index, action_index]\n",
        "    temporal_difference = reward + (discount_factor * np.max(q_values[row_index, column_index])) - old_q_value\n",
        "\n",
        "    #update the Q-value for the previous state and action pair\n",
        "    new_q_value = old_q_value + (learning_rate * temporal_difference)\n",
        "    q_values[old_row_index, old_column_index, action_index] = new_q_value\n",
        "\n",
        "print('Training complete!')\n",
        "\n",
        "#display a few shortest paths\n",
        "print(get_shortest_path(3, 9)) #starting at row 3, column 9\n",
        "print(get_shortest_path(5, 0)) #starting at row 5, column 0\n",
        "print(get_shortest_path(9, 5)) #starting at row 9, column 5\n",
        "\n",
        "\n",
        "#display an example of reversed shortest path\n",
        "path = get_shortest_path(5, 2) #go to row 5, column 2\n",
        "path.reverse()\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concepts\n",
        "\n",
        "# Quantum State Representation: The states of the environment, which are classical data, need to be encoded into quantum states. This process is known as quantum embedding.\n",
        "# Quantum Circuit for Action Selection: Design a quantum circuit that takes the quantum state as input and outputs a superposition of actions with their amplitudes related to their Q-values. Measurement of this circuit's output then probabilistically gives you an action to take, with higher Q-value actions being more likely.\n",
        "# Quantum Experience Replay: The experience replay buffer might also be stored and processed quantum-mechanically, allowing for more efficient sampling and memory usage.\n",
        "# Hybrid Training: The training might involve a hybrid approach, where certain calculations are performed on a classical computer (like environment simulation), while the quantum computer handles the Q-value computation and optimization.\n",
        "#!pip install cirq\n",
        "import cirq\n",
        "\n",
        "# Create a quantum circuit\n",
        "qubit = cirq.GridQubit(1, 1)  # Define a qubit at grid position 0,0\n",
        "circuit = cirq.Circuit(\n",
        "    cirq.X(qubit)**0.5,  # Apply a square root of NOT gate\n",
        "    cirq.measure(qubit, key='result')  # Measure the qubit\n",
        ")\n",
        "\n",
        "# Display the circuit\n",
        "print(\"Circuit:\")\n",
        "print(circuit)\n",
        "\n",
        "# Simulate the circuit\n",
        "simulator = cirq.Simulator()\n",
        "result = simulator.run(circuit, repetitions=10)\n",
        "\n",
        "# Print the results\n",
        "print(\"Results:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ImQbCcS-zZP",
        "outputId": "a6754ed0-1e85-494a-d0c0-2e0428387ab1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Circuit:\n",
            "(1, 1): ───X^0.5───M('result')───\n",
            "Results:\n",
            "result=1111010101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing mine\n",
        "\n",
        "import cirq\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, BatchNormalization, Reshape\n",
        "\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test, scaler, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = scaler.inverse_transform(y_pred)\n",
        "    y_test_inv = scaler.inverse_transform(y_test)\n",
        "    mse = mean_squared_error(y_test_inv, y_pred, multioutput='raw_values')\n",
        "    mae = mean_absolute_error(y_test_inv, y_pred, multioutput='raw_values')\n",
        "    print(f\"{model_name} - MSE por junta: {mse}\")\n",
        "    print(f\"{model_name} - MAE por junta: {mae}\\n\")\n",
        "\n",
        "# Load and prepare the data\n",
        "df = pd.read_csv('/content/help(v4).csv', encoding='utf8')\n",
        "\n",
        "# Define inputs and outputs\n",
        "total_columns = df.shape[1]\n",
        "num_labels = 6  # Number of labels\n",
        "num_features = total_columns - num_labels\n",
        "\n",
        "X = df.iloc[:, :num_features]\n",
        "y = df.iloc[:, -num_labels:]\n",
        "\n",
        "# Normalization\n",
        "x_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "X_s = x_scaler.fit_transform(X)\n",
        "y_s = y_scaler.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2)\n",
        "\n",
        "# Define the quantum circuit\n",
        "def create_quantum_circuit(repetitions=200):\n",
        "    qubit = cirq.GridQubit(0, 0)\n",
        "    circuit = cirq.Circuit(cirq.H(qubit), cirq.measure(qubit, key='result'))\n",
        "    simulator = cirq.Simulator()\n",
        "    result = simulator.run(circuit, repetitions=repetitions)\n",
        "    measurements = result.measurements['result']\n",
        "    return np.array(measurements).astype(np.float32).flatten()\n",
        "\n",
        "# Generate quantum features for training data\n",
        "quantum_features_train = create_quantum_circuit(repetitions=X_train.shape[0])\n",
        "\n",
        "# Integrate quantum features with training data\n",
        "X_train_quantum = np.hstack((X_train, quantum_features_train.reshape(-1, 1)))\n",
        "\n",
        "# Define and compile the MLP model\n",
        "def build_mlp_model(input_shape, output_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(2048, activation='relu', input_shape=(input_shape,)),\n",
        "        BatchNormalization(),\n",
        "        tf.keras.layers.Dense(output_shape, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(0.000005), loss='mean_squared_error', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "mlp_model = build_mlp_model(input_shape=X_train_quantum.shape[1], output_shape=y_train.shape[1])\n",
        "\n",
        "# Train the MLP model\n",
        "history = mlp_model.fit(X_train_quantum, y_train, epochs=200, validation_split=0.2)\n",
        "\n",
        "# Plotting the training history\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Training MSE')\n",
        "plt.plot(history.history['val_loss'], label='Validation MSE')\n",
        "plt.title('MSE per Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Generate quantum features for test data\n",
        "quantum_features_test = create_quantum_circuit(repetitions=X_test.shape[0])\n",
        "\n",
        "# Integrate quantum features with test data\n",
        "X_test_quantum = np.hstack((X_test, quantum_features_test.reshape(-1, 1)))\n",
        "\n",
        "# Evaluate the model with the test data\n",
        "evaluate_model(mlp_model, X_test_quantum, y_test, y_scaler, \"MLP Model\")\n"
      ],
      "metadata": {
        "id": "EXc_9gNtCYHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cirq\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test, scaler, model_name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = scaler.inverse_transform(y_pred)\n",
        "    y_test_inv = scaler.inverse_transform(y_test)\n",
        "    mse = mean_squared_error(y_test_inv, y_pred, multioutput='raw_values')\n",
        "    mae = mean_absolute_error(y_test_inv, y_pred, multioutput='raw_values')\n",
        "    print(f\"{model_name} - MSE por junta: {mse}\")\n",
        "    print(f\"{model_name} - MAE por junta: {mae}\\n\")\n",
        "\n",
        "# Load and prepare the data\n",
        "df = pd.read_csv('/content/Dataset_enhanced_Gaussiano_sem_Angulo_e_TransPoly_Normalizados.csv', encoding='utf8')\n",
        "\n",
        "# Define inputs and outputs\n",
        "total_columns = df.shape[1]\n",
        "num_labels = 6  # Number of labels\n",
        "num_features = total_columns - num_labels\n",
        "\n",
        "X = df.iloc[:, :num_features]\n",
        "y = df.iloc[:, -num_labels:]\n",
        "\n",
        "# Normalization\n",
        "x_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "X_s = x_scaler.fit_transform(X)\n",
        "y_s = y_scaler.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2)\n",
        "\n",
        "# Define the quantum circuit\n",
        "def create_quantum_circuit(repetitions=200):\n",
        "    qubit = cirq.GridQubit(0, 0)\n",
        "    circuit = cirq.Circuit(cirq.H(qubit), cirq.measure(qubit, key='result'))\n",
        "    simulator = cirq.Simulator()\n",
        "    result = simulator.run(circuit, repetitions=repetitions)\n",
        "    measurements = result.measurements['result']\n",
        "    return np.array(measurements).astype(np.float32).flatten()\n",
        "\n",
        "# Generate quantum features for training data\n",
        "quantum_features_train = create_quantum_circuit(repetitions=X_train.shape[0])\n",
        "\n",
        "# Integrate quantum features with training data\n",
        "X_train_quantum = np.hstack((X_train, quantum_features_train.reshape(-1, 1)))\n",
        "\n",
        "# Define and compile the MLP model\n",
        "def build_mlp_model(input_shape, output_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(32, activation='relu', input_shape=(input_shape,)),\n",
        "        tf.keras.layers.Dense(125, activation='relu'),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(output_shape, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "mlp_model = build_mlp_model(input_shape=X_train_quantum.shape[1], output_shape=y_train.shape[1])\n",
        "\n",
        "# Train the MLP model\n",
        "history = mlp_model.fit(X_train_quantum, y_train, epochs=100, validation_split=0.2)\n",
        "\n",
        "# Plotting the training history\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Training MSE')\n",
        "plt.plot(history.history['val_loss'], label='Validation MSE')\n",
        "plt.title('MSE per Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Generate quantum features for test data\n",
        "quantum_features_test = create_quantum_circuit(repetitions=X_test.shape[0])\n",
        "\n",
        "# Integrate quantum features with test data\n",
        "X_test_quantum = np.hstack((X_test, quantum_features_test.reshape(-1, 1)))\n",
        "\n",
        "# Evaluate the model with the test data\n",
        "evaluate_model(mlp_model, X_test_quantum, y_test, y_scaler, \"MLP Model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xhIR-YgrHbTU",
        "outputId": "8eb63ba1-0760-47c4-9b1d-376a9d381f18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.1166 - accuracy: 0.6077 - val_loss: 0.0270 - val_accuracy: 0.7987\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.8248 - val_loss: 0.0115 - val_accuracy: 0.8600\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.8698 - val_loss: 0.0068 - val_accuracy: 0.8913\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.8931 - val_loss: 0.0048 - val_accuracy: 0.9112\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9136 - val_loss: 0.0038 - val_accuracy: 0.9169\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9261 - val_loss: 0.0030 - val_accuracy: 0.9225\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.9302 - val_loss: 0.0025 - val_accuracy: 0.9381\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.9355 - val_loss: 0.0022 - val_accuracy: 0.9400\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.9397 - val_loss: 0.0019 - val_accuracy: 0.9337\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.9463 - val_loss: 0.0015 - val_accuracy: 0.9488\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.9488 - val_loss: 0.0013 - val_accuracy: 0.9494\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9513 - val_loss: 0.0011 - val_accuracy: 0.9506\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 9.5298e-04 - accuracy: 0.9542 - val_loss: 9.3391e-04 - val_accuracy: 0.9550\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 8.0097e-04 - accuracy: 0.9608 - val_loss: 7.7833e-04 - val_accuracy: 0.9625\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 6.9628e-04 - accuracy: 0.9631 - val_loss: 7.1340e-04 - val_accuracy: 0.9563\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 5.9619e-04 - accuracy: 0.9684 - val_loss: 5.9207e-04 - val_accuracy: 0.9694\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 5.1821e-04 - accuracy: 0.9677 - val_loss: 5.1484e-04 - val_accuracy: 0.9650\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 4.5254e-04 - accuracy: 0.9702 - val_loss: 5.5195e-04 - val_accuracy: 0.9569\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.8909e-04 - accuracy: 0.9705 - val_loss: 4.0408e-04 - val_accuracy: 0.9700\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 3.3349e-04 - accuracy: 0.9750 - val_loss: 3.4182e-04 - val_accuracy: 0.9744\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.2835e-04 - accuracy: 0.9769 - val_loss: 3.6287e-04 - val_accuracy: 0.9750\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 2.7753e-04 - accuracy: 0.9761 - val_loss: 2.9874e-04 - val_accuracy: 0.9750\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 2.4645e-04 - accuracy: 0.9787 - val_loss: 2.8771e-04 - val_accuracy: 0.9750\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 2.2791e-04 - accuracy: 0.9777 - val_loss: 2.7424e-04 - val_accuracy: 0.9769\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.9988e-04 - accuracy: 0.9802 - val_loss: 2.1884e-04 - val_accuracy: 0.9812\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.9448e-04 - accuracy: 0.9817 - val_loss: 2.1882e-04 - val_accuracy: 0.9750\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.9879e-04 - accuracy: 0.9814 - val_loss: 2.6165e-04 - val_accuracy: 0.9744\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.7145e-04 - accuracy: 0.9817 - val_loss: 1.8598e-04 - val_accuracy: 0.9794\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.6400e-04 - accuracy: 0.9803 - val_loss: 1.6269e-04 - val_accuracy: 0.9825\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.5427e-04 - accuracy: 0.9816 - val_loss: 1.6990e-04 - val_accuracy: 0.9787\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.4048e-04 - accuracy: 0.9828 - val_loss: 1.7295e-04 - val_accuracy: 0.9831\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.3681e-04 - accuracy: 0.9825 - val_loss: 1.5771e-04 - val_accuracy: 0.9812\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.5162e-04 - accuracy: 0.9823 - val_loss: 1.2026e-04 - val_accuracy: 0.9787\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.3240e-04 - accuracy: 0.9836 - val_loss: 1.2014e-04 - val_accuracy: 0.9819\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.1787e-04 - accuracy: 0.9834 - val_loss: 8.5467e-05 - val_accuracy: 0.9856\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 1.2554e-04 - accuracy: 0.9837 - val_loss: 1.0921e-04 - val_accuracy: 0.9844\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.0688e-04 - accuracy: 0.9837 - val_loss: 1.1639e-04 - val_accuracy: 0.9775\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.1245e-04 - accuracy: 0.9842 - val_loss: 1.3442e-04 - val_accuracy: 0.9819\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.1984e-04 - accuracy: 0.9858 - val_loss: 1.1672e-04 - val_accuracy: 0.9837\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.1062e-04 - accuracy: 0.9845 - val_loss: 1.0366e-04 - val_accuracy: 0.9812\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 1.0002e-04 - accuracy: 0.9861 - val_loss: 9.9657e-05 - val_accuracy: 0.9800\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 9.0142e-05 - accuracy: 0.9850 - val_loss: 1.0102e-04 - val_accuracy: 0.9806\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.2167e-04 - accuracy: 0.9825 - val_loss: 8.7399e-05 - val_accuracy: 0.9850\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 8.8836e-05 - accuracy: 0.9850 - val_loss: 8.7890e-05 - val_accuracy: 0.9831\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 8.5486e-05 - accuracy: 0.9875 - val_loss: 1.1019e-04 - val_accuracy: 0.9812\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 9.3681e-05 - accuracy: 0.9867 - val_loss: 7.5983e-05 - val_accuracy: 0.9837\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 9.1487e-05 - accuracy: 0.9850 - val_loss: 8.9870e-05 - val_accuracy: 0.9850\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 8.6233e-05 - accuracy: 0.9867 - val_loss: 9.8786e-05 - val_accuracy: 0.9875\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.0818e-04 - accuracy: 0.9825 - val_loss: 1.2333e-04 - val_accuracy: 0.9850\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.1559e-04 - accuracy: 0.9822 - val_loss: 7.2540e-05 - val_accuracy: 0.9862\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 6.6994e-05 - accuracy: 0.9870 - val_loss: 9.2565e-05 - val_accuracy: 0.9806\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.1437e-04 - accuracy: 0.9825 - val_loss: 8.2653e-05 - val_accuracy: 0.9862\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 9.7817e-05 - accuracy: 0.9848 - val_loss: 5.9273e-05 - val_accuracy: 0.9887\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 8.7114e-05 - accuracy: 0.9859 - val_loss: 9.7071e-05 - val_accuracy: 0.9812\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 1.0437e-04 - accuracy: 0.9828 - val_loss: 1.6921e-04 - val_accuracy: 0.9825\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 8.1384e-05 - accuracy: 0.9845 - val_loss: 6.1040e-05 - val_accuracy: 0.9862\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.0499e-05 - accuracy: 0.9862 - val_loss: 1.0988e-04 - val_accuracy: 0.9837\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 6.5363e-05 - accuracy: 0.9867 - val_loss: 9.8852e-05 - val_accuracy: 0.9819\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 8.3953e-05 - accuracy: 0.9873 - val_loss: 9.8063e-05 - val_accuracy: 0.9837\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 9.6505e-05 - accuracy: 0.9819 - val_loss: 1.0685e-04 - val_accuracy: 0.9844\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.5659e-05 - accuracy: 0.9881 - val_loss: 8.0734e-05 - val_accuracy: 0.9862\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 8.5923e-05 - accuracy: 0.9862 - val_loss: 1.2254e-04 - val_accuracy: 0.9812\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.0163e-04 - accuracy: 0.9864 - val_loss: 7.5336e-05 - val_accuracy: 0.9856\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.8993e-05 - accuracy: 0.9856 - val_loss: 9.3542e-05 - val_accuracy: 0.9850\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.4101e-05 - accuracy: 0.9864 - val_loss: 8.3493e-05 - val_accuracy: 0.9837\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.2195e-05 - accuracy: 0.9872 - val_loss: 7.1325e-05 - val_accuracy: 0.9844\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 8.4767e-05 - accuracy: 0.9852 - val_loss: 5.7651e-05 - val_accuracy: 0.9881\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 9.4746e-05 - accuracy: 0.9828 - val_loss: 1.0622e-04 - val_accuracy: 0.9844\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 8.1374e-05 - accuracy: 0.9864 - val_loss: 8.6177e-05 - val_accuracy: 0.9825\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.8030e-05 - accuracy: 0.9869 - val_loss: 5.4605e-05 - val_accuracy: 0.9875\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.4155e-05 - accuracy: 0.9886 - val_loss: 5.3252e-05 - val_accuracy: 0.9887\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 9.0651e-05 - accuracy: 0.9850 - val_loss: 7.1051e-05 - val_accuracy: 0.9906\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 8.6757e-05 - accuracy: 0.9852 - val_loss: 9.4589e-05 - val_accuracy: 0.9850\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 5.7872e-05 - accuracy: 0.9883 - val_loss: 4.5951e-05 - val_accuracy: 0.9887\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.1179e-05 - accuracy: 0.9850 - val_loss: 5.2326e-05 - val_accuracy: 0.9869\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 8.0096e-05 - accuracy: 0.9855 - val_loss: 7.1299e-05 - val_accuracy: 0.9887\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 9.0002e-05 - accuracy: 0.9848 - val_loss: 6.0031e-05 - val_accuracy: 0.9869\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 6.4150e-05 - accuracy: 0.9867 - val_loss: 4.1747e-05 - val_accuracy: 0.9875\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 7.1413e-05 - accuracy: 0.9872 - val_loss: 1.0337e-04 - val_accuracy: 0.9856\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 8.5365e-05 - accuracy: 0.9845 - val_loss: 6.7796e-05 - val_accuracy: 0.9887\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 8.6576e-05 - accuracy: 0.9836 - val_loss: 8.4636e-05 - val_accuracy: 0.9856\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.7387e-05 - accuracy: 0.9839 - val_loss: 6.8197e-05 - val_accuracy: 0.9912\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.2183e-05 - accuracy: 0.9873 - val_loss: 1.4887e-04 - val_accuracy: 0.9787\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 7.2662e-05 - accuracy: 0.9855 - val_loss: 6.1535e-05 - val_accuracy: 0.9887\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 9.6434e-05 - accuracy: 0.9866 - val_loss: 8.4524e-05 - val_accuracy: 0.9825\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 6.6808e-05 - accuracy: 0.9884 - val_loss: 5.1968e-05 - val_accuracy: 0.9887\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 6.9040e-05 - accuracy: 0.9850 - val_loss: 9.4599e-05 - val_accuracy: 0.9800\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.4848e-05 - accuracy: 0.9862 - val_loss: 5.8874e-05 - val_accuracy: 0.9875\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 7.9640e-05 - accuracy: 0.9853 - val_loss: 1.1044e-04 - val_accuracy: 0.9862\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 6.9702e-05 - accuracy: 0.9881 - val_loss: 4.1876e-05 - val_accuracy: 0.9894\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 8.0524e-05 - accuracy: 0.9861 - val_loss: 6.2164e-05 - val_accuracy: 0.9894\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 6.1177e-05 - accuracy: 0.9859 - val_loss: 5.6338e-05 - val_accuracy: 0.9869\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 9.0724e-05 - accuracy: 0.9848 - val_loss: 6.8924e-05 - val_accuracy: 0.9812\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 5.5688e-05 - accuracy: 0.9880 - val_loss: 4.6581e-05 - val_accuracy: 0.9900\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 8.4146e-05 - accuracy: 0.9867 - val_loss: 1.0248e-04 - val_accuracy: 0.9856\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 6.8053e-05 - accuracy: 0.9873 - val_loss: 1.3090e-04 - val_accuracy: 0.9837\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 7.3929e-05 - accuracy: 0.9873 - val_loss: 8.5375e-05 - val_accuracy: 0.9856\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 6.1287e-05 - accuracy: 0.9845 - val_loss: 9.1552e-05 - val_accuracy: 0.9819\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 0s 1ms/step - loss: 6.8923e-05 - accuracy: 0.9869 - val_loss: 1.1524e-04 - val_accuracy: 0.9869\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 7.9930e-05 - accuracy: 0.9855 - val_loss: 3.8111e-05 - val_accuracy: 0.9931\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 897us/step\n",
            "MLP Model - MSE por junta: [0.00036475 0.00017115 0.00022399 0.00093359 0.0002458  0.00097487]\n",
            "MLP Model - MAE por junta: [0.0138168  0.01022663 0.01172963 0.02225751 0.01233634 0.02155299]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
